{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "N = 1000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "input_tensor = torch.from_numpy(np.random.randn(BATCH_SIZE, N, 6))\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.8662e-02,  4.5610e-01,  7.5849e-01, -6.6844e-01, -1.3341e+00,\n",
       "          -1.1276e+00],\n",
       "         [-8.2324e-01,  1.4886e+00, -2.8042e-01, -6.2625e-01,  2.3411e-01,\n",
       "           4.2446e-01],\n",
       "         [ 1.6296e+00, -1.1479e+00,  6.8195e-01,  3.0234e-01, -1.9702e+00,\n",
       "           3.1512e-01],\n",
       "         ...,\n",
       "         [-1.1495e-03,  2.8762e+00,  3.9889e+00,  6.5679e-02, -8.4006e-03,\n",
       "           6.4628e-02],\n",
       "         [ 3.7032e-01, -4.8984e-01, -7.1102e-01,  2.0448e+00, -1.4769e+00,\n",
       "           1.0503e+00],\n",
       "         [ 5.8644e-01, -1.6471e+00,  7.0661e-01,  3.2984e-01,  5.0743e-01,\n",
       "          -1.1102e+00]],\n",
       "\n",
       "        [[-1.6351e+00,  7.9396e-01, -1.3316e-01,  8.4952e-01,  5.2459e-01,\n",
       "           2.7926e+00],\n",
       "         [-7.4857e-01, -2.2557e+00, -1.2342e+00, -4.1128e-01, -1.8901e-01,\n",
       "           8.4099e-01],\n",
       "         [ 5.3728e-01,  1.5114e+00, -6.1631e-03, -1.7430e+00,  3.9369e-02,\n",
       "          -2.7631e-01],\n",
       "         ...,\n",
       "         [ 7.9584e-01, -6.0985e-01,  4.6350e-01,  1.5528e-01, -1.4785e-02,\n",
       "           6.3856e-01],\n",
       "         [-1.2340e+00,  2.1557e+00,  1.3072e+00,  6.8885e-01, -4.6684e-01,\n",
       "           2.9720e-01],\n",
       "         [ 7.7092e-01,  7.1561e-01, -4.7974e-01,  7.5787e-01,  7.7792e-01,\n",
       "          -5.0736e-01]],\n",
       "\n",
       "        [[-2.8976e-01, -7.0994e-01,  1.7109e+00,  2.6507e-02,  1.1749e-01,\n",
       "          -1.8492e-01],\n",
       "         [-8.3030e-01,  1.8907e+00, -1.4547e+00, -7.9177e-01, -9.6777e-01,\n",
       "           2.0378e+00],\n",
       "         [-2.9517e+00, -3.1791e-01,  4.2123e+00, -4.5092e-01,  1.1567e+00,\n",
       "           4.6842e-01],\n",
       "         ...,\n",
       "         [ 1.5944e+00,  3.9282e-01, -1.0257e+00, -1.2883e+00, -3.1780e-01,\n",
       "           4.3203e-01],\n",
       "         [-3.4623e-01, -1.2261e+00,  1.0161e-02,  6.9220e-01, -5.9585e-01,\n",
       "           5.7210e-01],\n",
       "         [-2.2649e-01,  5.0271e-03,  1.4390e+00,  6.5215e-01, -2.6171e-01,\n",
       "          -1.2210e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7104e+00,  1.1398e-01,  6.4538e-01, -2.4178e-01, -8.3401e-01,\n",
       "          -7.7808e-01],\n",
       "         [-1.6753e+00,  3.6501e-01,  7.1603e-01,  1.5953e-01,  2.4594e-01,\n",
       "          -1.1573e+00],\n",
       "         [-6.7805e-02, -1.6965e-02, -3.1956e-01, -6.3483e-01,  5.7157e-01,\n",
       "           1.0998e-01],\n",
       "         ...,\n",
       "         [ 7.2662e-01, -3.6461e-01,  1.2901e+00, -2.2639e-01, -9.9878e-01,\n",
       "          -1.4350e+00],\n",
       "         [-6.6976e-01, -1.4568e+00,  1.6484e+00,  5.5380e-01, -4.0858e-01,\n",
       "           8.6469e-01],\n",
       "         [ 7.9320e-01, -1.1940e+00, -1.8559e+00, -1.3030e+00, -1.7823e-01,\n",
       "          -7.4223e-01]],\n",
       "\n",
       "        [[-1.2696e+00,  5.7331e-01,  1.8033e-01, -6.9342e-01, -2.2755e+00,\n",
       "           5.8799e-01],\n",
       "         [-3.9072e-01, -8.1421e-01, -2.6044e-01, -3.2277e-01,  1.2390e+00,\n",
       "          -2.8001e-01],\n",
       "         [ 5.4698e-01,  4.7948e-01, -2.4576e-01,  4.1409e-01, -6.1109e-01,\n",
       "          -9.6018e-01],\n",
       "         ...,\n",
       "         [ 8.3585e-01, -8.2759e-01,  2.3313e-01,  8.3227e-02,  2.4389e-01,\n",
       "           1.0782e-01],\n",
       "         [ 4.3244e-01, -2.1423e-03, -1.2125e+00,  4.7274e-01, -2.9932e-01,\n",
       "           1.9521e+00],\n",
       "         [-2.9516e-01,  1.5749e+00, -8.3901e-02,  3.1061e+00, -9.6608e-01,\n",
       "          -1.0879e+00]],\n",
       "\n",
       "        [[ 3.2026e-01,  1.4204e+00,  2.4527e-02,  6.4179e-01,  5.0413e-01,\n",
       "          -5.8043e-01],\n",
       "         [ 1.3496e-02,  2.3254e-01, -8.8102e-01, -7.8880e-01, -1.3814e+00,\n",
       "          -1.6687e+00],\n",
       "         [-6.0894e-01,  2.1587e+00, -1.3333e+00, -5.7715e-01, -1.2801e-02,\n",
       "           1.0910e+00],\n",
       "         ...,\n",
       "         [ 6.0209e-01, -1.4539e+00, -1.5606e+00,  6.1048e-01, -6.6895e-01,\n",
       "           8.7727e-01],\n",
       "         [-1.5467e+00,  4.4280e-01, -1.0839e+00,  1.4656e-02, -5.1376e-01,\n",
       "           4.1754e-01],\n",
       "         [-3.1533e-01, -1.7486e+00, -2.8401e-01,  4.7137e-02, -5.6330e-01,\n",
       "          -2.4059e+00]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1247, -0.0652,  0.0201,  ..., -0.0105,  0.0046, -0.0442],\n",
       "         [-0.0353,  0.0922,  0.1211,  ...,  0.0997,  0.1731, -0.0684],\n",
       "         [ 0.1805, -0.0493, -0.0285,  ..., -0.0550, -0.0685,  0.2444],\n",
       "         ...,\n",
       "         [-0.0625, -0.0224, -0.1575,  ..., -0.0430, -0.0352, -0.0669],\n",
       "         [ 0.2053, -0.0062,  0.0166,  ...,  0.1175,  0.0891,  0.3206],\n",
       "         [ 0.1775, -0.1483, -0.0685,  ...,  0.0758, -0.0148,  0.0669]],\n",
       "\n",
       "        [[ 0.0887,  0.0904,  0.0448,  ...,  0.1209,  0.2378, -0.0486],\n",
       "         [ 0.2000,  0.0931,  0.0677,  ...,  0.3434,  0.2087,  0.1491],\n",
       "         [ 0.0672, -0.0762,  0.1291,  ...,  0.0276, -0.0469, -0.0030],\n",
       "         ...,\n",
       "         [ 0.1000, -0.0267, -0.0460,  ...,  0.0166,  0.0380,  0.0264],\n",
       "         [ 0.1528,  0.0670,  0.0469,  ...,  0.0552,  0.2333,  0.0395],\n",
       "         [ 0.0255, -0.1621,  0.0198,  ...,  0.1150,  0.0241, -0.0140]],\n",
       "\n",
       "        [[ 0.1525,  0.0755, -0.0461,  ...,  0.1662,  0.1240, -0.0700],\n",
       "         [ 0.2281,  0.1107,  0.1474,  ...,  0.1570,  0.2573, -0.0226],\n",
       "         [ 0.0366,  0.1086, -0.0409,  ...,  0.0506,  0.3351, -0.0455],\n",
       "         ...,\n",
       "         [ 0.1035, -0.0444,  0.0847,  ...,  0.1000,  0.0055, -0.0363],\n",
       "         [ 0.2289,  0.0523,  0.0219,  ...,  0.2411,  0.1916,  0.1771],\n",
       "         [ 0.1164, -0.2522, -0.0366,  ...,  0.0420,  0.0481, -0.0400]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3071, -0.1644, -0.0189,  ...,  0.0730, -0.0112,  0.0181],\n",
       "         [ 0.0662,  0.0138,  0.0726,  ...,  0.2016,  0.1791, -0.1115],\n",
       "         [ 0.0489, -0.1042,  0.0966,  ...,  0.2285,  0.2006, -0.0814],\n",
       "         ...,\n",
       "         [ 0.3299, -0.2503,  0.0072,  ...,  0.1325,  0.0204,  0.0199],\n",
       "         [ 0.1921,  0.0041, -0.0144,  ...,  0.1256,  0.1464,  0.1026],\n",
       "         [ 0.3186, -0.1639,  0.1510,  ...,  0.3212,  0.0599,  0.0585]],\n",
       "\n",
       "        [[ 0.2494, -0.0303,  0.0488,  ...,  0.0912,  0.1665,  0.0189],\n",
       "         [ 0.1142, -0.0022,  0.0668,  ...,  0.3079,  0.1624, -0.0724],\n",
       "         [ 0.1433, -0.1660,  0.0767,  ...,  0.1869,  0.0950, -0.0343],\n",
       "         ...,\n",
       "         [ 0.2787, -0.1478, -0.0089,  ...,  0.1686,  0.0357,  0.0373],\n",
       "         [ 0.3096,  0.0364,  0.0442,  ...,  0.2299,  0.1755,  0.1266],\n",
       "         [ 0.3579, -0.1735,  0.0852,  ...,  0.1465,  0.0792,  0.1454]],\n",
       "\n",
       "        [[ 0.0977, -0.1042,  0.0422,  ...,  0.1364,  0.0750, -0.0707],\n",
       "         [ 0.2708, -0.0951,  0.1169,  ...,  0.2533,  0.1481, -0.0150],\n",
       "         [ 0.0036,  0.0437,  0.1650,  ...,  0.1587,  0.2242, -0.0885],\n",
       "         ...,\n",
       "         [ 0.3521, -0.0574,  0.0394,  ...,  0.3280,  0.0966,  0.2863],\n",
       "         [ 0.3584,  0.1352,  0.0966,  ...,  0.2635,  0.2482,  0.0661],\n",
       "         [ 0.4434, -0.3754,  0.0544,  ...,  0.2958,  0.0747,  0.2045]]],\n",
       "       device='cuda:0', grad_fn=<CudnnRnnBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_DIM = 8\n",
    "\n",
    "input_tensor = input_tensor.float().cuda()\n",
    "\n",
    "lstm = nn.LSTM(input_size=6, hidden_size=HIDDEN_DIM).cuda()\n",
    "\n",
    "h_0 = Variable(torch.zeros(1, N, HIDDEN_DIM).cuda())\n",
    "c_0 = Variable(torch.zeros(1, N, HIDDEN_DIM).cuda())\n",
    "\n",
    "output, (final_hidden_state, final_cell_state) = lstm(input_tensor, (h_0, c_0))\n",
    "\n",
    "output # (batch_size, N, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=8, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_FC_DIM = 128\n",
    "OUTPUT_CLASSES = 6\n",
    "\n",
    "fc1 = nn.Linear(in_features=HIDDEN_DIM, out_features=HIDDEN_FC_DIM, device='cuda:0')\n",
    "fc2 = nn.Linear(in_features=HIDDEN_FC_DIM, out_features=OUTPUT_CLASSES, device='cuda:0')\n",
    "\n",
    "print(fc1)\n",
    "print(fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1493,  0.0191,  0.0975, -0.0962, -0.1928,  0.0627],\n",
       "         [ 0.1614,  0.0494,  0.1687, -0.0594, -0.2078,  0.0467],\n",
       "         [ 0.1394,  0.0243,  0.0994, -0.1109, -0.2258,  0.1081],\n",
       "         ...,\n",
       "         [ 0.1713,  0.0505,  0.1278, -0.0695, -0.1238,  0.0808],\n",
       "         [ 0.1617,  0.0656,  0.1691, -0.1305, -0.2065,  0.0898],\n",
       "         [ 0.1738,  0.0262,  0.1287, -0.0219, -0.1896,  0.0236]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fc1 = fc1(final_hidden_state.cuda())\n",
    "output_fc2 = fc2(output_fc1)\n",
    "output_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1493,  0.0191,  0.0975, -0.0962, -0.1928,  0.0627],\n",
       "        [ 0.1614,  0.0494,  0.1687, -0.0594, -0.2078,  0.0467],\n",
       "        [ 0.1394,  0.0243,  0.0994, -0.1109, -0.2258,  0.1081],\n",
       "        ...,\n",
       "        [ 0.1713,  0.0505,  0.1278, -0.0695, -0.1238,  0.0808],\n",
       "        [ 0.1617,  0.0656,  0.1691, -0.1305, -0.2065,  0.0898],\n",
       "        [ 0.1738,  0.0262,  0.1287, -0.0219, -0.1896,  0.0236]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_fc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1909, 0.1676, 0.1813, 0.1494, 0.1356, 0.1751],\n",
       "        [0.1892, 0.1691, 0.1906, 0.1517, 0.1308, 0.1687],\n",
       "        [0.1889, 0.1684, 0.1815, 0.1471, 0.1311, 0.1831],\n",
       "        ...,\n",
       "        [0.1891, 0.1676, 0.1811, 0.1486, 0.1408, 0.1728],\n",
       "        [0.1892, 0.1719, 0.1906, 0.1413, 0.1309, 0.1761],\n",
       "        [0.1924, 0.1660, 0.1839, 0.1582, 0.1338, 0.1656]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "F.softmax(output_fc2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13551765, 0.17521291, 0.18641994, 0.179433  , 0.1804226 ,\n",
       "       0.14299389])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax\n",
    "odds = np.exp([-0.1938,  0.0631,  0.1251,  0.0869,  0.0924, -0.1401])\n",
    "odds / sum(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999900000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.13551765, 0.17521291, 0.18641994, 0.179433  , 0.1804226 , 0.14299389])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0,\n",
       "        0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 5,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output_fc2[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(output_fc2[0], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.randn((3, 100, 128))\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8915,  1.7832,  1.6524,  ..., -0.8731,  0.5819, -0.8361],\n",
       "        [-0.0215, -1.5740, -2.0229,  ...,  1.7967, -1.0117,  0.4433],\n",
       "        [ 0.9838, -0.0976, -0.6290,  ...,  1.0066,  0.1958,  0.5359],\n",
       "        ...,\n",
       "        [-0.4473,  0.9761,  1.1862,  ..., -1.5912,  0.0228,  0.3670],\n",
       "        [ 0.1478,  0.1996, -0.6642,  ..., -0.5052,  2.0963,  0.0787],\n",
       "        [ 0.3492,  1.3791, -0.5362,  ...,  0.6132, -0.2500,  0.7660]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.permute(1, 0, 2).reshape(h.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8915,  1.7832,  1.6524,  ..., -0.8731,  0.5819, -0.8361],\n",
       "        [-0.0215, -1.5740, -2.0229,  ...,  1.7967, -1.0117,  0.4433],\n",
       "        [ 0.9838, -0.0976, -0.6290,  ...,  1.0066,  0.1958,  0.5359],\n",
       "        ...,\n",
       "        [-0.4473,  0.9761,  1.1862,  ..., -1.5912,  0.0228,  0.3670],\n",
       "        [ 0.1478,  0.1996, -0.6642,  ..., -0.5052,  2.0963,  0.0787],\n",
       "        [ 0.3492,  1.3791, -0.5362,  ...,  0.6132, -0.2500,  0.7660]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((h[-3,:,:], h[-2,:,:], h[-1,:,:]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 1000\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_CLASSES = 6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_tensor = torch.from_numpy(np.random.randn(BATCH_SIZE, SEQUENCE_LEN, 6))\n",
    "input_tensor = input_tensor.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(hidden_size=HIDDEN_DIM,\n",
    "                       output_size=OUTPUT_CLASSES,\n",
    "                       device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0422,  0.0892, -0.0681,  0.0000, -0.0000,  0.0000],\n",
       "        [-0.0000,  0.0458, -0.0000,  0.1071, -0.0525,  0.0968],\n",
       "        [-0.0579,  0.0545, -0.0259,  0.1015, -0.0461,  0.0000],\n",
       "        [-0.0000,  0.0614, -0.0489,  0.0716, -0.0000,  0.0000],\n",
       "        [-0.0774,  0.0351, -0.0000,  0.0000, -0.0424,  0.0815],\n",
       "        [-0.0558,  0.0458, -0.0000,  0.1155, -0.0437,  0.0000],\n",
       "        [-0.0000,  0.0506, -0.0575,  0.0924, -0.0391,  0.0000],\n",
       "        [-0.0238,  0.0446, -0.0528,  0.0895, -0.0145,  0.0869],\n",
       "        [-0.0000,  0.0498, -0.0368,  0.0000, -0.0277,  0.0673],\n",
       "        [-0.0567,  0.0609, -0.0516,  0.1048, -0.0260,  0.0939],\n",
       "        [-0.0000,  0.0511, -0.0000,  0.0794, -0.0000,  0.0000],\n",
       "        [-0.0835,  0.0624, -0.0000,  0.0000, -0.0361,  0.0000],\n",
       "        [-0.0520,  0.0430, -0.0308,  0.0000, -0.0048,  0.1088],\n",
       "        [-0.0000,  0.0000, -0.0000,  0.0803, -0.0279,  0.1015],\n",
       "        [-0.0712,  0.0494, -0.0000,  0.0953, -0.0442,  0.0000],\n",
       "        [-0.0524,  0.0000, -0.0451,  0.0980, -0.0278,  0.0875],\n",
       "        [-0.0488,  0.0601, -0.0559,  0.0000, -0.0459,  0.0863],\n",
       "        [-0.0378,  0.0534, -0.0396,  0.0702, -0.0267,  0.0991],\n",
       "        [-0.0000,  0.0587, -0.0527,  0.0787, -0.0000,  0.0857],\n",
       "        [-0.0000,  0.0622, -0.0747,  0.0000, -0.0373,  0.1009],\n",
       "        [-0.0628,  0.0672, -0.0489,  0.0773, -0.0548,  0.0826],\n",
       "        [-0.0419,  0.0734, -0.0000,  0.0781, -0.0309,  0.0000],\n",
       "        [-0.0304,  0.0679, -0.0508,  0.0000, -0.0000,  0.0971],\n",
       "        [-0.0523,  0.0671, -0.0000,  0.0000, -0.0000,  0.0923],\n",
       "        [-0.0521,  0.0636, -0.0666,  0.0871, -0.0088,  0.1085],\n",
       "        [-0.0515,  0.0579, -0.0527,  0.0856, -0.0164,  0.0000],\n",
       "        [-0.0614,  0.0190, -0.0457,  0.1053, -0.0524,  0.1053],\n",
       "        [-0.0596,  0.0744, -0.0416,  0.0000, -0.0379,  0.1233],\n",
       "        [-0.0000,  0.0000, -0.0404,  0.0000, -0.0361,  0.0000],\n",
       "        [-0.0742,  0.0617, -0.0000,  0.0888, -0.0368,  0.0769],\n",
       "        [-0.0386,  0.0618, -0.0491,  0.1087, -0.0405,  0.0798],\n",
       "        [-0.0833,  0.0552, -0.0500,  0.1167, -0.0301,  0.0000],\n",
       "        [-0.0361,  0.0000, -0.0328,  0.0000, -0.0000,  0.1048],\n",
       "        [-0.0377,  0.0669, -0.0457,  0.0852, -0.0000,  0.1139],\n",
       "        [-0.0292,  0.0471, -0.0663,  0.0699, -0.0284,  0.0891],\n",
       "        [-0.0363,  0.0571, -0.0526,  0.0000, -0.0128,  0.0000],\n",
       "        [-0.0425,  0.0736, -0.0371,  0.0882, -0.0069,  0.1074],\n",
       "        [-0.0601,  0.0756, -0.0000,  0.0926, -0.0112,  0.1016],\n",
       "        [-0.0525,  0.0589, -0.0520,  0.0839, -0.0376,  0.0974],\n",
       "        [-0.0621,  0.0608, -0.0559,  0.0000, -0.0000,  0.0969],\n",
       "        [-0.0428,  0.0000, -0.0707,  0.0909, -0.0276,  0.0899],\n",
       "        [-0.0483,  0.0629, -0.0605,  0.1132, -0.0159,  0.0880],\n",
       "        [-0.0000,  0.0463, -0.0790,  0.1034, -0.0334,  0.0904],\n",
       "        [-0.0635,  0.0000, -0.0470,  0.1013, -0.0311,  0.0958],\n",
       "        [-0.0537,  0.0518, -0.0474,  0.0000, -0.0000,  0.1062],\n",
       "        [-0.0184,  0.0529, -0.0000,  0.0000, -0.0000,  0.1195],\n",
       "        [-0.0448,  0.0387, -0.0464,  0.1223, -0.0158,  0.1010],\n",
       "        [-0.0661,  0.0746, -0.0000,  0.0932, -0.0233,  0.0000],\n",
       "        [-0.0610,  0.0725, -0.0000,  0.1037, -0.0132,  0.0906],\n",
       "        [-0.0368,  0.0377, -0.0000,  0.0618, -0.0073,  0.0865],\n",
       "        [-0.0636,  0.0592, -0.0735,  0.0000, -0.0403,  0.0740],\n",
       "        [-0.0486,  0.0595, -0.0441,  0.0836, -0.0161,  0.0956],\n",
       "        [-0.0480,  0.0571, -0.0000,  0.0000, -0.0000,  0.1208],\n",
       "        [-0.0386,  0.0477, -0.0581,  0.0812, -0.0322,  0.0800],\n",
       "        [-0.0431,  0.0399, -0.0718,  0.0721, -0.0289,  0.0000],\n",
       "        [-0.0000,  0.0000, -0.0588,  0.1050, -0.0000,  0.1087],\n",
       "        [-0.0707,  0.0651, -0.0356,  0.0000, -0.0116,  0.0909],\n",
       "        [-0.0000,  0.0704, -0.0587,  0.0792,  0.0000,  0.0831],\n",
       "        [-0.0463,  0.0000, -0.0613,  0.0000, -0.0302,  0.0860],\n",
       "        [-0.0659,  0.0686, -0.0644,  0.0978, -0.0279,  0.0872],\n",
       "        [-0.0601,  0.0633, -0.0552,  0.0967, -0.0000,  0.0000],\n",
       "        [-0.0661,  0.0382, -0.0224,  0.0867, -0.0238,  0.0912],\n",
       "        [-0.0600,  0.0387, -0.0617,  0.0976, -0.0000,  0.1053],\n",
       "        [-0.0715,  0.0693, -0.0625,  0.1211,  0.0203,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(input_tensor)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.argmax(logits.squeeze(1), dim=-1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = torch.randint(0, OUTPUT_CLASSES, (BATCH_SIZE,), device=device)\n",
    "y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.dtype, y_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.1849, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = preds.float()\n",
    "y_labels = y_labels.float()\n",
    "\n",
    "loss = criterion(y_preds, y_labels)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      2\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\joona\\Documents\\Git Repos\\gyro-rnn-test\\.venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\joona\\Documents\\Git Repos\\gyro-rnn-test\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
